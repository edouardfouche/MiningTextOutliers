/*
 * Copyright (C) 2020 Edouard Fouché
 *
 * This program is free software: you can redistribute it and/or modify
 * it under the terms of the GNU Affero General Public License as published by
 * the Free Software Foundation, either version 3 of the License, or
 * (at your option) any later version.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
 * GNU Affero General Public License for more details.
 *
 * You should have received a copy of the GNU Affero General Public License
 * along with this program. If not, see <http://www.gnu.org/licenses/>.
 */
package io.github.edouardfouche.experiments

import java.io.{File, FileWriter}

import breeze.stats.DescriptiveStats.percentile
import io.github.edouardfouche.detectors._
import io.github.edouardfouche.experiments.Data._
import io.github.edouardfouche.index.ElkiKNN
import io.github.edouardfouche.preprocess.{DataSet, WordQuality}
import io.github.edouardfouche.utils
import io.github.edouardfouche.utils._

/**
  *
  */
object Exploit_KJNN   extends Experiment {
  def run(): Unit = {
    info(s"Starting com.edouardfouche.experiments ${this.getClass.getSimpleName}")

    val maxk = 30

    val corruption = 0.0 // -> important, no corruption
    val k = 30
    val j = 30
    val p = 0.9

    val datasets = Vector("nyt_1", "arxiv_cs")

    val stop_source =  scala.io.Source.fromFile(fetch(s"/stopwords.txt"))
    val stopwords: Array[String] = stop_source.getLines().toArray
    stop_source.close()

    for {
      dataset <- datasets.par
    } {
      val (words_emb, docs_emb, docs_labels, docstrings, vec2word) = open(dataset)
      val allwords: DataSet = words_emb.open()
      val docs: DataSet = docs_emb.open()
      val labelswithoutliers: Array[Double] = docs_labels.open()(0)
      val classes: Array[Double] = labelswithoutliers.distinct.filter(_ != 0.0)
      val labels: Array[Double] = labelswithoutliers.map(x => if(x == 0.0) scala.util.Random.shuffle(classes.toList).head else x)
      val documents = docstrings

      info(s"Starting with NYT, c: ${corruption}")

      val corruptedlabels: Array[Double] = corruptlabels(labels, corruption)
      val alldocs = docs.columns.transpose
      info(s"alldocs.length : ${alldocs.length}, labels.length: ${corruptedlabels.length}")
      val labeldict: Map[Vector[Double], Int] = alldocs.zip(corruptedlabels).map(x => x._1.toVector -> x._2.toInt).toMap

      //val words = allwords
      val words: DataSet = new DataSet(allwords.columns.transpose.filter(x => !stopwords.contains(vec2word(x.toVector))).transpose)
      info(s"Pruned ${allwords.nrows - words.nrows} words (words.ncols: ${words.ncols}, words.nrows: ${words.nrows})")

      info(s"Getting repscores, c=${corruption}")
      val allrepscores: Map[Double, Map[String, Double]] = new WordQuality(documents,
        phraseintegrity, corruptedlabels).estimate()
      val repscores = allrepscores

      info(s"Examples, c=${corruption}:")
      repscores.keys.foreach { k =>
        val top = repscores(k).toArray.sortBy(x => -x._2).take(10)
        info(s"Cell $k, top: ${top mkString ";"}")
      }

      info(s"Caching kNN results with ${words_emb.id.split("_")(0)}...")

      info(s"Proportions c=${corruption}: ${labels.groupBy(identity).map(x => (x._1.toInt, x._2.length)).mkString(";")}")

      val rstarwords = ElkiKNN(words)
      val rstardocs = ElkiKNN(docs)

      rstarwords.fillcache(alldocs, maxk)
      rstardocs.fillcache(alldocs, maxk)

      val detector = W1KJNN(rstarwords, rstardocs, labeldict, vec2word, repscores, 1, 1)
      info(s"Cache for ${detector.id} is ready !")

      detector.setkj(k, j)
      val (cpu, wall, unfilteredscores: Array[(Int, Double)]) = StopWatch.measureTime(detector.computeScores(alldocs))
      val entropies: Array[Double] = unfilteredscores.map(_._2)

      val entropythreshold = percentile(entropies, p)

      val scores: Array[(Int, Double)] = unfilteredscores.zip(corruptedlabels).map(x => if (x._1._2 <= entropythreshold) x._1 else (0, x._1._2 ))

      utils.createFolderIfNotExisting(experiment_folder + "/patterns")

      for{
        labelindexesindexes <- scores.zipWithIndex.sortBy(- _._1._2).zipWithIndex.par
      } {
        val i = labelindexesindexes._2
        val ii = labelindexesindexes._1._2
        if(scores(ii)._1 == 0) { // this is a reported Type A outlier
          val docstring = documents(ii)

          val pathA = experiment_folder + "/patterns/" + s"${dataset}_typeA_${i+1}_${ii+1}.txt"
          val fileA = new File(pathA)
          val fwA = new FileWriter(fileA, true)

          info(s"Handling Type A outlier n°${i+1}, (position ${ii+1})")

          fwA.write(s"Type A outlier n°${i+1}, (position ${ii+1}): $docstring\n")

          val similarDocuments = detector.getSimilarDocuments(alldocs(ii), k)
          val similarDocumentsEmb: Array[Vector[Double]] = similarDocuments.map(_._1.toVector)
          val docindexes = alldocs.zipWithIndex.filter(x => similarDocumentsEmb.contains(x._1.toVector)).map(_._2)

          val customlabels = labels.zipWithIndex.map(x => if(docindexes.contains(x._2)) 1.0 else 0.0)

          val (cpu, wall, customrepscores: Map[Double, Map[String, Double]]) = StopWatch.measureTime(new WordQuality(documents,
            phraseintegrity, customlabels).estimate())
          fwA.write(s"Estimated top words in $wall ms\n")

          val topcustomwords: Array[(String, Double)] = customrepscores(1.0).toArray.sortBy(x => -x._2).take(100)

          fwA.write(s"Representative words: ${topcustomwords mkString ","}\n")

          val docwords = docstring.split(" ")
          fwA.write(s"Representativeness of each word: ${docwords.map(x => (x, customrepscores(1.0).getOrElse(x, 0.0))) mkString ","}\n")

          fwA.write(s"Found ${docindexes.length} similar documents:\n")
          docindexes.zip(similarDocuments).take(5).foreach{x =>
            fwA.write(s"Similarity: ${x._2._2}, (position ${x._1}), ${documents(x._1)}\n")
          }
          fwA.flush()
          fwA.close()

          val attributes = List("dataset", "type", "i", "ii", "cpu", "wall", "forecasted", "actual", "entropy")
          val summary = ExperimentSummary(attributes)
          summary.add("dataset", dataset)
          summary.add("type", "A")
          summary.add("i", i+1)
          summary.add("ii", ii+1)
          summary.add("cpu", cpu)
          summary.add("wall", wall)
          summary.add("forecasted", scores(ii)._1)
          summary.add("actual", labelswithoutliers(ii))
          summary.add("entropy", scores(ii)._2)
          summary.write(summaryPath)
        }
      }

      for{
        labelindexesindexes <- scores.zipWithIndex.sortBy(_._1._2).zipWithIndex.par
      } {
        val i = labelindexesindexes._2
        val ii = labelindexesindexes._1._2
        if((scores(ii)._1 != corruptedlabels(ii)) & (scores(ii)._1 != 0)) { // this is a reported Type B outlier

          val pathB = experiment_folder + "/patterns/" + s"${dataset}_typeB_${i+1}_${ii+1}.txt"
          val fileB = new File(pathB)
          val fwB = new FileWriter(fileB, true)

          val docstring = documents(ii)
          info(s"Handling Type B outlier n°${i+1}, (position ${ii+1})")

          fwB.write(s"Type B outlier n°${i+1} (${corruptedlabels(ii)} -> ${scores(ii)}): $docstring \n")

          val similarDocuments = detector.getSimilarDocuments(alldocs(ii), k)
          val similarDocumentsEmb: Array[Vector[Double]] = similarDocuments.map(_._1.toVector)
          val docindexes = alldocs.zipWithIndex.filter(x => similarDocumentsEmb.contains(x._1.toVector)).map(_._2)

          val customlabels = labels.zipWithIndex.map(x => if(docindexes.contains(x._2)) 1.0 else 0.0)

          val (cpu, wall, customrepscores: Map[Double, Map[String, Double]]) = StopWatch.measureTime(new WordQuality(documents,
            phraseintegrity, customlabels).estimate())
          fwB.write(s"Estimated top words in $wall ms\n")

          val topcustomwords: Array[(String, Double)] = customrepscores(1.0).toArray.sortBy(x => -x._2).take(100)

          fwB.write(s"Representative words: ${topcustomwords mkString ","}\n")

          val docwords = docstring.split(" ")
          fwB.write(s"Representativeness of each word: ${docwords.map(x => (x, customrepscores(1.0).getOrElse(x, 0.0))) mkString ","}\n")

          fwB.write(s"Found ${docindexes.length} similar documents:\n")
          docindexes.zip(similarDocuments).take(5).foreach{x =>
            fwB.write(s"Similarity: ${x._2._2}, (position ${x._1}), ${documents(x._1)}\n")
          }
          fwB.flush()
          fwB.close()

          val attributes = List("dataset", "type", "i", "ii", "cpu", "wall", "forecasted", "actual", "entropy")
          val summary = ExperimentSummary(attributes)
          summary.add("dataset", dataset)
          summary.add("type", "B")
          summary.add("i", i+1)
          summary.add("ii", ii+1)
          summary.add("cpu", cpu)
          summary.add("wall", wall)
          summary.add("forecasted", scores(ii)._1)
          summary.add("actual", labelswithoutliers(ii))
          summary.add("entropy", scores(ii)._2)
          summary.write(summaryPath)
        }
      }
    }


    info(s"End of experiment ${this.getClass.getSimpleName} - ${formatter.format(java.util.Calendar.getInstance().getTime)}")
  }
}
